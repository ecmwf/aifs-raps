#!/bin/bash

cd $(dirname "$0")
pwd

set -eu
source ../../../.aifsenv

printenv

train_end_yyyymmdd=202010
val_start_yyyymmdd=202011
val_end_yyyymmdd=202012

num_channels=1024
num_gpus=4
num_nodes=1
ens_size=2 #ens size 0 to disable
num_gpus_per_model=2 #ens_size * num_gpus_per_model cant be more than num_gpus

dataset=aifs-ea-an-oper-0001-mars-n320-1979-2022-6h-v6.zarr

jobid=$$
jobname=aifs_n320
host=${RAPS_SYSTEM:-""}

hydra_args=""


mapper_chunks=1 #32 for 1N
proc_chunks=1 #8 for 1N

export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
export FAKE_IO=0

$RAPS_AIFS_ROOT_DIR/bin/train \
    -j "$jobid" -J "$jobname" \
    --num-nodes="$num_nodes" --num-gpus="$num_gpus" \
    --train-batch-limit=30 --max-epochs=1 --ens=$ens_size \
    --train-end=$train_end_yyyymmdd --val-start=$val_start_yyyymmdd --val-end=$val_end_yyyymmdd \
    --num-gpus-per-model="$num_gpus_per_model" -C "$num_channels" -p "16-mixed" \
     --num-mapper-chunks=$mapper_chunks --num-processor-chunks=$proc_chunks \
    --dataset="$dataset" --interactive --num-workers=4 --rollout 1 --hydra-args="$hydra_args" "$@"

exit $?
